# On-the-fly autonomous control of neutron diffraction via physics-informed Bayesian active learning

## ABSTRACT

æˆ‘ã€…ã¯ã€è‡ªå¾‹åž‹ä¸­æ€§å­å›žæŠ˜å®Ÿé¨“è£…ç½®ANDiEã‚’é–‹ç™ºãƒ»é…å‚™ã—ã€ä¸­æ€§å­å›žæŠ˜å®Ÿé¨“ã‚’ãƒ©ã‚¤ãƒ–ã§è‡ªå¾‹çš„ã«åˆ¶å¾¡ã™ã‚‹ã“ã¨ã‚’åˆã‚ã¦å®Ÿè¨¼ã—ãŸã€‚
ä¸­æ€§å­æ•£ä¹±ã¯ã€ç‰©è³ªã®ç£æ°—æ§‹é€ ã¨æŒ™å‹•ã‚’èª¿ã¹ã‚‹ãŸã‚ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ã§æ±Žç”¨æ€§ã®é«˜ã„ç‰¹æ€§è©•ä¾¡æŠ€è¡“ã§ã‚ã‚‹ã€‚
ã—ã‹ã—ã€ä¸–ç•Œã®ä¸­æ€§å­æ•£ä¹±å®Ÿé¨“æ–½è¨­ã¯é™ã‚‰ã‚Œã¦ãŠã‚Šã€ã¾ãŸã€ãã®ã‚ˆã†ãªæ–½è¨­ã§ã¯å¸¸ã«éŽå‰°ãªéœ€è¦ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã€‚
æˆ‘ã€…ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹æ¸¬å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®è‡ªå¾‹çš„ãªãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ã§ã€ä¸­æ€§å­å›žæŠ˜å®Ÿé¨“ã«å¿…è¦ãªæ™‚é–“ã‚’å¤§å¹…ã«çŸ­ç¸®ã™ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã™ã‚‹ã€‚
äº‹å‰ã®ç§‘å­¦çš„çŸ¥è­˜ã¨ãƒ™ã‚¤ã‚ºåž‹èƒ½å‹•å­¦ç¿’ã«ã‚ˆã£ã¦ã€æ¸¬å®šã®é †åºã‚’å‹•çš„ã«åˆ¶å¾¡ã™ã‚‹ã€‚
ANDiEã¯ã€MnOã¨Fe1.09Teã®ç£æ°—ç§©åºè»¢ç§»ã‚’å®Ÿé¨“çš„ã«æ±ºå®šã—ã€åŒæ™‚ã«æ¸¬å®šåŠ¹çŽ‡ã‚’5å€å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚
ã•ã‚‰ã«ã€ä»®èª¬æ¤œè¨¼ã®å¾Œå‡¦ç†ã¨ã—ã¦ã€ANDiEã¯å¯èƒ½æ€§ã®ã‚ã‚‹ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®é›†åˆã‹ã‚‰è»¢ç§»æŒ™å‹•ã‚’æ±ºå®šã™ã‚‹ã“ã¨ãŒã§ããŸã€‚
ANDiEã®èƒ½å‹•çš„å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€æ§˜ã€…ãªä¸­æ€§å­å®Ÿé¨“ã«åºƒãé©ç”¨ã§ãã€ææ–™æŽ¢ç´¢ã‚’åŠ é€Ÿã™ã‚‹ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ä¸­æ€§å­æ•£ä¹±ã®æ‰‰ã‚’é–‹ãã“ã¨ãŒã§ãã‚‹ã€‚

## I. INTRODUCTION

ãƒ™ã‚¤ã‚ºåž‹è‡ªå¾‹çš„ç‰©ç†ç§‘å­¦ã¯ã€æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã‚‹æ–°ã—ã„åˆ†é‡Žã§ã‚ã‚Šã€çŸ¥è­˜ã®ç²å¾—ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¤§å¹…ã«åŠ é€Ÿã™ã‚‹ã“ã¨ã§ã€ç§‘å­¦çš„æ‰‹æ³•å…¨ä½“ã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ã‚’ç§˜ã‚ã¦ã„ã‚‹ã€‚
è‡ªå¾‹çš„ç‰©ç†ç§‘å­¦ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãŒå®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆ¶å¾¡ã—ã€æœ€ã‚‚æƒ…å ±é‡ã®å¤šã„å®Ÿé¨“ã‚’é¸æŠžã—ã€å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ã‚‹ã€‚
å®Ÿé¨“å®¤ã«ãŠã‘ã‚‹è‡ªå¾‹çš„å®Ÿé¨“ã®æœ€åˆã®å…·ä½“ä¾‹ã¨ã—ã¦ã¯ã€ç§»å‹•åž‹ãƒ­ãƒœãƒƒãƒˆåŒ–å­¦è€…1ã€åŒ–å­¦åˆæˆã®ãŸã‚ã®è‡ªå‹•é‹è»¢å®Ÿé¨“å®¤2ã€è‡ªå¾‹çš„æ©Ÿæ¢°è¨­è¨ˆã‚·ã‚¹ãƒ†ãƒ 3ã€ã‚«ãƒ¼ãƒœãƒ³ãƒŠãƒŽãƒãƒ¥ãƒ¼ãƒ–æˆé•·ã®ãŸã‚ã®æœ€é©åŒ–ãƒ„ãƒ¼ãƒ«4ãªã©ãŒã‚ã‚‹ã€‚
æœ€è¿‘ã§ã¯ã€è‡ªå¾‹åž‹æ”¾å°„å…‰å›žæŠ˜ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³5,6ãŒè¡Œã‚ã‚Œã€äººå·¥çŸ¥èƒ½ï¼ˆAIï¼‰ä¸»å°Žã®å®Ÿé¨“ã®èˆžå°ã¯ã€å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸå®Ÿé¨“ãƒ“ãƒ¼ãƒ ã‚¿ã‚¤ãƒ ãŒè²´é‡ãªå•†å“ã§ã‚ã‚‹å›½ç«‹ç ”ç©¶æ‰€ã®ãƒ“ãƒ¼ãƒ ãƒ©ã‚¤ãƒ³ç’°å¢ƒã¸ã¨åºƒãŒã£ã¦ã„ã‚‹ã€‚

ç‰¹ã«ä¸­æ€§å­æ•£ä¹±ã§ã¯ã€æ¸¬å®šæ™‚é–“ã®çŸ­ç¸®ã¨ãƒªã‚½ãƒ¼ã‚¹ã®å‰Šæ¸›ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚
ä¸­æ€§å­å›žæŠ˜ã¯ã€ç£æ°—ç§©åºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç›´æŽ¥è¦³æ¸¬ã§ãã‚‹æ•°å°‘ãªã„æ¸¬å®šæŠ€è¡“ã®ä¸€ã¤ã§ã‚ã‚‹ã€‚
ç£æ°—ç§©åºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€ç£æ°—ç§©åºçŠ¶æ…‹ã‹ã‚‰ç„¡ç§©åºçŠ¶æ…‹ã¸ã®é·ç§»æŒ™å‹•ã‚’è¨˜è¿°ã™ã‚‹ã€‚
ã“ã®ç£æ°—ç§©åºè»¢ç§»ãŒã©ã®ã‚ˆã†ã«ã€ã©ã®ã‚ˆã†ãªæ¸©åº¦ã§èµ·ã“ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ã“ã¨ã¯ã€æ–°ã—ã„ç£æ€§ææ–™ã®ç™ºè¦‹ã«ã¨ã£ã¦éžå¸¸ã«é‡è¦ã§ã‚ã‚‹ã€‚
ãã®ãŸã‚ã€ä¸­æ€§å­ç§‘å­¦æ–½è¨­ã®ãƒ“ãƒ¼ãƒ ã‚¿ã‚¤ãƒ ã¯éžå¸¸ã«é‡è¦è¦–ã•ã‚Œã¦ã„ã‚‹ã€‚
ã—ã‹ã—ã€ã“ã®å¼·åŠ›ãªæŠ€è¡“ã¯ã€ä¸–ç•Œã§ã‚‚ã»ã‚“ã®ä¸€æ¡ã‚Šã®æ–½è¨­ã§ã—ã‹åˆ©ç”¨ã§ããšã€éœ€è¦ãŒä¾›çµ¦ã‚’ã¯ã‚‹ã‹ã«ä¸Šå›žã£ã¦ã„ã‚‹ã®ãŒç¾çŠ¶ã§ã‚ã‚‹ã€‚

ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç ”ç©¶ã™ã‚‹ãƒ“ãƒ¼ãƒ ãƒ©ã‚¤ãƒ³å®Ÿé¨“ã§ã¯ã€ä¸€èˆ¬çš„ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé©åˆ‡ãªæƒ…å ±ã‚’è¦‹é€ƒã•ãªã„ã‚ˆã†ã«ã¨ã€åºƒã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç¯„å›²ã¨é«˜ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°ã‚’å®šç¾©ã—ã€ã‚¢ãƒ‰ãƒ›ãƒƒã‚¯ã«å®šç¾©ã•ã‚ŒãŸç¶²ç¾…çš„ãªæ¸¬å®šã‚’è¡Œã†ã€‚
ç¾åœ¨ã€ã“ã‚Œã‚‰ã®æ¸¬å®šã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã«ã¤ã„ã¦ã€æ™®éçš„ã«åˆæ„ã•ã‚ŒãŸæ–¹æ³•ã¯ãªã„ã€‚
ã“ã®ã‚¢ãƒ‰ãƒ›ãƒƒã‚¯ãªã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¯ã€å›žæŠ˜ä¿¡å·ãŒå¼·ãã€è©¦æ–™ãŒã‚ˆãçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã«ã¯ã‚ã¾ã‚Šå•é¡Œã«ã¯ãªã‚‰ãªã„ãŒã€ä¿¡å·ãŒå°ã•ã„è©¦æ–™ï¼ˆå°ã•ãªç£æ°—ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã€å°ã•ãªçµæ™¶ã€è–„ã„è†œãªã©ï¼‰ã‚„è©¦æ–™ã«ã¤ã„ã¦ã»ã¨ã‚“ã©çŸ¥ã‚‰ã‚Œã¦ã„ãªã„å ´åˆã«ã¯åŠ¹æžœãŒãªãã€ç„¡é§„ãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
ã“ã®ç ”ç©¶ã®ç›®çš„ã®ä¸€ã¤ã¯ã€æ¸¬å®šå€¤ã‹ã‚‰å¼•ãå‡ºã›ã‚‹çµ±è¨ˆçš„æŽ¨è«–ã«åŸºã¥ã„ã¦æ¸¬å®šå€¤ã‚’é¸æŠžã™ã‚‹ã“ã¨ã‚’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„ã«å®šå¼åŒ–ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
å¾“æ¥ã®ã‚¢ãƒ‰ãƒ›ãƒƒã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã¯ã€å…¨ãƒ‡ãƒ¼ã‚¿ãŒåŽé›†ã•ã‚Œã‚‹ã¨ã€å°‚é–€å®¶ãŒè¨ˆç®—ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’è§£æžã—ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ã€‚
é«˜ãƒ•ãƒ©ãƒƒã‚¯ã‚¹ã®æ•£ä¹±å®Ÿé¨“ï¼ˆä¾‹ãˆã°ã€æ”¾å°„å…‰Xç·šå›žæŠ˜æ¸¬å®šï¼‰ã§ã¯ã€åŽé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å¤§é‡ã‹ã¤é«˜é€ŸãªãŸã‚ã€é©åˆ‡ãªç§‘å­¦çš„æƒ…å ±ã‚’è¿…é€Ÿã«è§£æ˜Žã™ã‚‹ãŸã‚ã®æ©Ÿæ¢°å­¦ç¿’ãŒå¿…è¦ã¨ãªã‚‹7,8ã€‚
ã—ã‹ã—ã€ä¸­æ€§å­å›žæŠ˜å®Ÿé¨“ã®ãƒ•ãƒ©ãƒƒã‚¯ã‚¹ã¯ä¸€èˆ¬çš„ã«ã¯ã‚‹ã‹ã«ä½Žãã€ã—ãŸãŒã£ã¦ã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åŽé›†ã™ã‚‹ã“ã¨ã¯é¢å€’ã§æ™‚é–“ãŒã‹ã‹ã‚‹ã‚‚ã®ã§ã‚ã£ãŸã€‚
ã“ã®èª²é¡Œã¯ã€å…¸åž‹çš„ãªç¶²ç¾…çš„æ‰‹æ³•ã§ã¯å¿…è¦ãªé‡ã‚’ã¯ã‚‹ã‹ã«è¶…ãˆã‚‹æ¸¬å®šå€¤ãŒå¾—ã‚‰ã‚Œã‚‹ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼èª¿æŸ»ã«ä»£è¡¨ã•ã‚Œã‚‹ã€‚
ã“ã®ã‚ˆã†ãªèª²é¡Œã«å¯¾ã—ã¦ã€æ©Ÿæ¢°å­¦ç¿’ã¯ã€è‡ªå¾‹åˆ¶å¾¡ã«ã‚ˆã£ã¦å¾Œç¶šã®å„å®Ÿé¨“ã‚’ãã®å ´ã§æœ€é©åŒ–ã™ã‚‹ã“ã¨ã§ã€çŸ¥è­˜ç²å¾—ã‚’åŠ é€Ÿã™ã‚‹å½¹å‰²ã‚’æžœãŸã™ã“ã¨ãŒã§ãã‚‹ã€‚
æœ¬ç ”ç©¶ã§ã¯ã€è‡ªå¾‹åž‹ä¸­æ€§å­å›žæŠ˜å®Ÿé¨“è£…ç½®ï¼ˆANDiEï¼‰ã‚’é–‹ç™ºã—ã€ç£æ°—è»¢ç§»ã®æŒ™å‹•ã‚’è‡ªå·±ä¸»å°Žçš„ã«æŽ¢ç´¢ã—ã€æ¸¬å®šåŠ¹çŽ‡ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æˆåŠŸã—ãŸã€‚

ã“ã®ç ”ç©¶ã§ã¯ã€æœ€é©ãªå®Ÿé¨“è¨­è¨ˆï¼ˆé©å¿œè¨­è¨ˆï¼‰ã«ç‰¹åŒ–ã—ãŸAIã®ä¸€åˆ†é‡Žã§ã‚ã‚‹èƒ½å‹•å­¦ç¿’ï¼ˆALï¼‰9ã¨ç¢ºçŽ‡çš„ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€æ¸¬å®šé¸æŠžã‚’ãã®å ´ã§ã‚¬ã‚¤ãƒ‰ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€ã‚¤ãƒ³ã‚·ãƒªã‚³ã®è‡ªå¾‹çš„ãªã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã«ã‚ˆã‚Šã€ãƒ™ã‚¤ã‚ºæ‰‹æ³•ã‚’ä½¿ç”¨ã—ã¦ä¸­æ€§å­æ•£ä¹±æ¸¬å®šã®é †åºã‚’æ±ºå®šã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹10ã€‚
ã“ã®ç ”ç©¶ã§ã¯ã€äº‹å‰ã«åŽé›†ã—ãŸãƒ‡ãƒ¼ã‚¿é–“ã‚’è£œé–“ã™ã‚‹ãŸã‚ã«ã‚¬ã‚¦ã‚¹éŽç¨‹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
æœ¬ç ”ç©¶ã§ã¯ã€ä¸­æ€§å­æ•£ä¹±ã¨ç£æ°—ç‰©ç†ã®çŸ¥è­˜ã‚’å–ã‚Šå…¥ã‚ŒãŸç‰©ç†ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹è‡ªå¾‹çš„ãªãƒ©ã‚¤ãƒ–ä¸­æ€§å­æ•£ä¹±å®Ÿé¨“ã‚’åˆã‚ã¦å®Ÿè¨¼ã—ãŸã€‚
ç‰©ç†ãƒ™ãƒ¼ã‚¹ã®çŸ¥è­˜ã‚’ãƒžãƒ«ã‚³ãƒ•é€£éŽ–ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æ³•ï¼ˆMCMCï¼‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€ANDiEã¯ãã®å ´ã§è£œé–“ãƒ»å¤–æŒ¿ã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚
ã“ã®æ‰‹æ³•ã«ã‚ˆã‚Šã€æ¸¬å®šãƒ‡ãƒ¼ã‚¿ã®åŽé›†ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã«è‡³ã‚‹ã¾ã§ã€ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã‚’é€šã˜ã¦ä¸ç¢ºå®Ÿæ€§ã‚’æŠŠæ¡ã—ã€ä¼æ’­ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
ã•ã‚‰ã«ã€ANDiEã®MCMCãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã¯å…ˆè¡Œç‰©ç†ãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ãŠã‚Šã€è§£æžçµæžœã¯ç‰©ç†çš„ã«å®Ÿç¾å¯èƒ½ãªã‚‚ã®ã«é™å®šã•ã‚Œã¾ã™ã€‚
ã“ã‚Œã¯ã€ç§‘å­¦çš„AIï¼ˆSciAIï¼‰ã¨ã„ã†æ–°åˆ†é‡Žã®è¨­è¨ˆæŒ‡é‡ã«æ²¿ã£ãŸã‚‚ã®ã§ã‚ã‚‹11ã€‚
ã“ã®ã‚ˆã†ãªSciAIã«ã‚ˆã‚‹è‡ªå¾‹çš„ãªå®Ÿé¨“ã¯ã€ä¸­æ€§å­å›žæŠ˜å®Ÿé¨“ã«å¿…è¦ãªæ™‚é–“ã‚’å¤§å¹…ã«çŸ­ç¸®ã—ã€è£…ç½®ã‚„å°‚é–€å®¶ã®æ™‚é–“ã‚’è»½æ¸›ã™ã‚‹ã“ã¨ã§ã€ã‚ã‚‹æ–½è¨­ã§ã®å®Ÿé¨“ã‚’å¢—ã‚„ã—ãŸã‚Šã€ä»–ã®æ–¹æ³•ã§ã¯å®Ÿç¾ä¸å¯èƒ½ãªå®Ÿé¨“ã‚’å¯èƒ½ã«ã™ã‚‹å¯èƒ½æ€§ã‚’æŒã£ã¦ã„ã¾ã™ã€‚
ç§ãŸã¡ã¯ã€ANDiEãŒè‡ªå¾‹çš„ã«ãƒ©ã‚¤ãƒ–ä¸­æ€§å­å›žæŠ˜å®Ÿé¨“ã‚’è¡Œã„ã€ãƒãƒ¼ãƒ«æ¸©åº¦ï¼ˆTNï¼‰ã‚’ç™ºè¦‹ã—ã€ãã®å¾Œã®è©¦æ–™ã®ç£æ°—æ§‹é€ ã®æ¸©åº¦ä¾å­˜æ€§ã«é–¢ã™ã‚‹ä»®èª¬æ¤œè¨¼ã‚’ã€é€šå¸¸å¿…è¦ãªæ¸¬å®šæ•°ã®ç´„5åˆ†ã®1ã§è¡Œã†ã“ã¨ã«æˆåŠŸã—ãŸã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚

ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ«ãƒ¼ãƒ„ã¯18ä¸–ç´€ã«ã¾ã§é¡ã‚Šã€ãƒ©ãƒ—ãƒ©ã‚¹ãŒå¤©ä½“ã®ç ”ç©¶ã«ALã‚’ç”¨ã„ãŸã“ã¨ã«ã‚ã‚‹12ã€‚
ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãªã©ã®ãƒ™ã‚¤ã‚ºALæ‰‹æ³•ã¯ã€äºˆæ¸¬å€¤ã¨é–¢é€£ã™ã‚‹ä¸ç¢ºå®Ÿæ€§ã®ä¸¡æ–¹ã‚’å‡ºåŠ›ã™ã‚‹ãŸã‚ã«ã€ç¢ºçŽ‡çš„ãªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’çµ„ã¿è¾¼ã‚“ã§ã„ã‚‹ã€‚
ã“ã‚Œã‚‰ã®æ–¹æ³•ã¯ã€ç ”ç©¶å®¤ã‚„ã‚¤ãƒ³ã‚·ãƒªã‚³ã§æœªçŸ¥ã®æ©Ÿèƒ½ã‚’æœ€é©åŒ–ã™ã‚‹ç§‘å­¦è€…ã‚’å°Žãã®ã«ç‰¹ã«æœ‰ç”¨ã§ã‚ã‚‹13-19ã€‚
ææ–™ç§‘å­¦ã®åˆ†é‡Žã§ã¯ã€ææ–™æŽ¢ç´¢ã‚’åŠ é€Ÿã•ã›ã‚‹ãŸã‚ã«ã€è‡ªå¾‹çš„ãªå®Ÿé¨“ãŒæ€¥å‹™ã¨ãªã£ã¦ã„ã‚‹20ã€‚
è‡ªå¾‹ã‚·ã‚¹ãƒ†ãƒ ã®åŽŸå‹•åŠ›ã¨ã—ã¦ã€ALã¯ã€å¾“æ¥ã®AIæœ€é©åŒ–ã‚¹ã‚­ãƒ¼ãƒ ã‚’ç”¨ã„ã¦ã€ææ–™åŠ å·¥æ¡ä»¶ã®æœ€é©åŒ–4,21,22ã€è©¦æ–™ã®ç‰¹æ€§è©•ä¾¡6ã€æŠ€è¡“çš„å¿œç”¨ã®ãŸã‚ã®ãƒãƒªãƒžãƒ¼ã‚„æœ‰æ©Ÿåˆ†å­ã®çµ„æˆ1,2,23ã«æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚
è‡ªå¾‹ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹ã“ã‚Œã‚‰ã®å–ã‚Šçµ„ã¿ã®å¤šãã¯ã€ä¸»ã«åŒ–å­¦ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸã‚‚ã®ã§ã‚ã£ãŸ24-26ã€‚
å›ºä½“ææ–™ã®è‡ªå¾‹ã‚·ã‚¹ãƒ†ãƒ ã¨ã„ã†æ–°åˆ†é‡Žã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã¯ã€ææ–™æŽ¢ç´¢ã‚’åŠ é€Ÿã—ã€è¤‡é›‘ãªææ–™ã¨ç‰¹æ€§ã®é–¢ä¿‚ã‚’è§£æ˜Žã™ã‚‹ä¸Šã§ã€å¤§ããªæœŸå¾…ãŒå¯„ã›ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹27,28ã€‚
ã“ã‚Œã‚‰ã®AIãƒ„ãƒ¼ãƒ«ã«äº‹å‰ã®ç‰©ç†çš„çŸ¥è­˜ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã§ã€SciAIã¯è§£é‡ˆå¯èƒ½æ€§ã‚’ç¶­æŒã—ã¤ã¤ã€çŸ¥è­˜ã®å–å¾—ã‚’ã•ã‚‰ã«åŠ é€Ÿã•ã›ã‚‹ã¨ã„ã†å¤§ããªåˆ©ç‚¹ã‚’æœ‰ã—ã¦ã„ã‚‹ã€‚
ä¾‹ãˆã°ã€ææ–™æŽ¢ç´¢ã¨æœ€é©åŒ–ã®ãŸã‚ã®é–‰ãƒ«ãƒ¼ãƒ—è‡ªå¾‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆCAMEOï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ä½ç›¸ãƒžãƒƒãƒ”ãƒ³ã‚°ã¨Xç·šå›žæŠ˜ã®çŸ¥è­˜ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ææ–™æœ€é©åŒ–ã®åŠ é€Ÿã«ãŠã„ã¦éžSciAIæ‰‹æ³•ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒå®Ÿè¨¼ã•ã‚Œã€ã‚¯ãƒ©ã‚¹æœ€é«˜ã®ç›¸å¤‰åŒ–ãƒ¡ãƒ¢ãƒªææ–™ã‚’ç™ºè¦‹ã™ã‚‹çµæžœã¨ãªã£ãŸ5ã€‚

ANDiEã¯ã€ãƒ™ã‚¤ã‚ºåž‹SciAIã‚’æŽ¡ç”¨ã—ã€ä¸­æ€§å­å›žæŠ˜æ¸¬å®šã‹ã‚‰ç£æ°—ç§©åºå¤‰æ•°ã®æ±ºå®šã‚’é«˜é€ŸåŒ–ã—ãŸã€‚
ç£æ°—ç§©åºå¤‰æ•°ã¯ã€ç£æ°—ç§©åºè»¢ç§»ã®æŒ¯ã‚‹èˆžã„ã‚’è¨˜è¿°ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚
ä¾‹ãˆã°ã€1æ¬¡è»¢ç§»ã‚’ç¤ºã™åå¼·ç£æ€§ä½“ã¯æ¸©åº¦ã§ç§©åºå¤‰æ•°ãŒä¸é€£ç¶šã«ãªã‚Šã€2æ¬¡è»¢ç§»ã‚’ç¤ºã™åå¼·ç£æ€§ä½“ã¯æ¸©åº¦ã§ç§©åºå¤‰æ•°ãŒé€£ç¶šã«ãªã‚Šã€1æ¬¡å¾®åˆ†ãŒæ¸©åº¦ã§ä¸é€£ç¶šã«ãªã‚‹ã¨ã„ã£ãŸç¾è±¡ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚
å¯èƒ½ã§ã‚ã‚Œã°ã€äº‹å‰ã®ç£æ°—æ¸¬å®šã€ç†±å®¹é‡æ¸¬å®šã€è¼¸é€æ¸¬å®šã‹ã‚‰ã€ç£æ°—ç§©åºè»¢ç§»ãŒç¤ºå”†ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚
ä¸€æ–¹ã€ç£æ°—ç§©åºã¯ä¸­æ€§å­å›žæŠ˜ã§ç›´æŽ¥è¦³æ¸¬ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ç§©åºçŠ¶æ…‹ã«ãŠã‘ã‚‹ç£æ°—ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã‹ã‚‰æ•£ä¹±ã™ã‚‹ä¸­æ€§å­ã«ã‚ˆã£ã¦ã€ãƒ–ãƒ©ãƒƒã‚°å›žæŠ˜å¼·åº¦ãŒå¢—åŠ ã™ã‚‹ã‹ã‚‰ã§ã‚ã‚‹ã€‚
ã“ã®ãŸã‚ä¸­æ€§å­å›žæŠ˜ã¯ã€å‰è¿°ã®ãƒãƒ«ã‚¯è©•ä¾¡æ³•ã§ã¯æ¸¬å®šãŒå›°é›£ãªç‰©è³ªï¼ˆè–„è†œè©¦æ–™ã‚„ä¸ç´”ç‰©ç›¸ã‚’å«ã‚€è©¦æ–™ãªã©ï¼‰ã®ç£æ°—ç§©åºåŒ–ã‚’ç ”ç©¶ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
ã—ãŸãŒã£ã¦ã€ä¸­æ€§å­å›žæŠ˜ã¯ç£æ°—ç§©åºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨TNã‚’æ±ºå®šã™ã‚‹ãŸã‚ã®æœ€ã‚‚æ±ºå®šçš„ãªæ¸¬å®šæŠ€è¡“ã§ã‚ã‚‹ã€‚
ANDiEã¯ã€TNã®äº‹å‰åˆ†å¸ƒã‚’çŸ¥ã‚‹ãŸã‚ã«ã‚ã‚‰ã‚†ã‚‹äºˆå‚™çš„ãªç‰¹æ€§è©•ä¾¡æ¸¬å®šã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã€ãã‚Œã«ã‚ˆã‚Šã€æƒ…å ±é‡ã®å¤šã„ãƒ‡ãƒ¼ã‚¿ã¨æ­£ã—ã„TNå€¤ã‚’ã‚ˆã‚Šæ—©ãåŽæŸã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã‚‹ã€‚
ã•ã‚‰ã«ã€ã“ã®ä¸­æ€§å­å›žæŠ˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã«ã¯ã„ãã¤ã‹ã®ã‚ˆãçŸ¥ã‚‰ã‚ŒãŸç‰©ç†åŽŸç†ãŒã‚ã‚Šã€ã“ã‚Œã‚‰ã¯ç§©åºå¤‰æ•°ã®è‡ªå¾‹çš„ç™ºè¦‹ã®ãŸã‚ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«çµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚
ã“ã‚Œã‚‰ã«ã¯ã€å›žæŠ˜å¼·åº¦ãŒãƒã‚¢ã‚½ãƒ³åž‹ã®ä¸ç¢ºã‹ã•ã‚’æŒã¤ã“ã¨ã€å›žæŠ˜ãƒ”ãƒ¼ã‚¯ãŒç–‘ä¼¼ãƒœã‚¤ã‚°ãƒˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚ˆãè¨˜è¿°ã•ã‚Œã‚‹ã“ã¨ã€å›žæŠ˜å¼·åº¦ã®ç£æ°—æˆåˆ†ãŒç£åŒ–ã®äºŒä¹—ã«é–¢ä¿‚ã™ã‚‹ã“ã¨ã€ãªã©ãŒå«ã¾ã‚Œã‚‹29ã€‚
é‡è¦ãªã®ã¯ã€ç£åŒ–ã®æ¸©åº¦ä¾å­˜æ€§ãŒæ•°ç¨®é¡žã®ãƒ¢ãƒ‡ãƒ«ã«å¾“ã†ã¨ã„ãˆã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
äº‹å‰ã®ç‰©ç†çš„çŸ¥è­˜ãŒã©ã®ã‚ˆã†ã«ç¬¦å·åŒ–ã•ã‚Œã‚‹ã‹ã«ã¤ã„ã¦ã®èª¬æ˜Žã¯ã€ç¬¬IIéƒ¨ã«ã‚ã‚‹ã€‚

å›žæŠ˜å®Ÿé¨“ã¯ã€ã¾ãšè»¢ç§»æ¸©åº¦ä»¥ä¸Šã‹ã‚‰5Kã®ãƒ™ãƒ¼ã‚¹æ¸©åº¦ã¾ã§å†·å´ã™ã‚‹ã“ã¨ã‹ã‚‰å§‹ã‚ã‚‰ã‚Œã‚‹ã€‚
ãã®å¾Œã®å„åå¾©ã«ãŠã„ã¦ã€ç‰©ç†ãƒ™ãƒ¼ã‚¹ã®ä¸ç¢ºå®šæ€§å®šé‡åŒ–ã«ã‚ˆã‚Šã€ç£æ°—æ§‹é€ ãƒ”ãƒ¼ã‚¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãã®æ¸©åº¦ä¾å­˜æ€§ã®çŸ¥è­˜ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«ã€ãã®å¾Œã®ç­‰æ¸©å›žæŠ˜æ¸¬å®šã®é¸æŠžã‚’ã‚¬ã‚¤ãƒ‰ã™ã‚‹ã€‚
ã“ã®æ‰‹æ³•ã¯ã€ç£æ°—æ§‹é€ è§£æžã®ãŸã‚ã®ç­‰æ¸©ãƒ™ã‚¤ã‚ºæŽ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã¨ã€æ¸©åº¦ä¾å­˜æ€§è§£æžã®ãŸã‚ã®ç¬¬2ã®ç†±ãƒ™ã‚¤ã‚ºæŽ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµ„ã¿åˆã‚ã›ã¦ã„ã‚‹ã€‚
å¾“æ¥ã®èƒ½å‹•å­¦ç¿’ã‚¹ã‚­ãƒ¼ãƒ ã§ã¯ã€æœ€é©ãªæ¸¬å®šã‚’è¡Œã†ãŸã‚ã«ä»»æ„ã®æ¸©åº¦ã‚’é¸æŠžã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã‚ã£ãŸãŒã€ã“ã®èª²é¡Œã§ã¯ãã®ã‚ˆã†ãªã‚¹ã‚­ãƒ¼ãƒ ã¯ä¸å¯èƒ½ã§ã‚ã‚‹ã€‚
ä¸€æ¬¡ç›¸è»¢ç§»ã¯ãƒ’ã‚¹ãƒ†ãƒ¬ãƒ†ã‚£ãƒƒã‚¯ã§ã‚ã‚‹ãŸã‚ã€æ¸¬å®šã•ã‚Œã‚‹TNã¯è©¦æ–™ãŒæ¸©ã¾ã£ã¦ã„ã‚‹ã‹å†·ãˆã¦ã„ã‚‹ã‹ã«ä¾å­˜ã™ã‚‹ã€‚
ã•ã‚‰ã«ã€TNä»¥ä¸‹ã®ç§©åºå¤‰æ•°ã¯ã“ã®ãƒ’ã‚¹ãƒ†ãƒ¬ãƒ†ã‚£ãƒƒã‚¯ãªæ€§è³ªã®ãŸã‚ã€ä¸€åº¦è©¦æ–™ã‚’ãƒ™ãƒ¼ã‚¹æ¸©åº¦ä»¥ä¸Šã«æ¸©ã‚ãŸã‚‰ã€ç§©åºå¤‰æ•°ãŒåŒã˜çŠ¶æ…‹ã«ãªã‚‹ã‚ˆã†ã«å†·å´ã™ã‚‹å‰ã«TNã‚ˆã‚Šååˆ†ã«é«˜ãæ¸©ã‚ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚
ã“ã®æ‰‹é †ã¯æ³•å¤–ã«ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚ç‰¹ã«ã€å®Ÿé¨“ã®ç›®çš„ãŒTNã‚’ç™ºè¦‹ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã“ã¨ã‚’è€ƒãˆã‚‹ã¨ã€ç„¡ç§©åºçŠ¶æ…‹ã‚’ç¢ºå®Ÿã«é”æˆã™ã‚‹ãŸã‚ã«ã¯ã€åŠ ç†±ã‚¹ãƒ†ãƒƒãƒ—ã‚’éŽå¤§è©•ä¾¡ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
ã“ã‚Œã«ã‚ˆã‚Šã€æ¸©åº¦ã®ç„¡åˆ¶é™ãªæŽ¢ç´¢ã®å¯èƒ½æ€§ãŒé˜»ã¾ã‚Œã‚‹ã€‚
ãã“ã§ã€ç§ãŸã¡ã¯ã€å–å¾—é–¢æ•°ã‚’åˆ¶é™ã—ã¦ã€åŸºæº–æ¸©åº¦ã‹ã‚‰æ¸©åº¦ã‚’ä¸Šæ˜‡ã•ã›ã‚‹ã ã‘ã«ã—ãŸã€‚
å®Ÿé¨“æ¸©åº¦ãŒæŽ¨å®šã•ã‚ŒãŸTNã‚’å¤§ããä¸Šå›žã‚Šã€ãã‚Œä»¥ä¸Šã®æƒ…å ±ãŒå¾—ã‚‰ã‚Œãªããªã‚‹ã¾ã§ã€æ¸¬å®šãƒ—ãƒ­ã‚»ã‚¹ãŒç¹°ã‚Šè¿”ã•ã‚Œã‚‹ã€‚
å›³1ã«ANDiEæ–¹å¼ã®æ§‹æˆå›³ã‚’ç¤ºã™ã€‚

FIG. 1.
: è‡ªå¾‹åž‹ä¸­æ€§å­å›žæŠ˜è£…ç½®ANDiEï¼ˆAutonomous neutron diffraction explorerï¼‰ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å›³ã€‚
ANDiEã¯ã€ãƒãƒ¼ãƒ«æ¸©åº¦ï¼ˆTNï¼‰ã‚’ç™ºè¦‹ã—ã€ãã®å¾Œã®ç£æ°—æ§‹é€ ã®æ¸©åº¦ä¾å­˜æ€§ã®ä»®èª¬æ¤œè¨¼ã‚’è¡Œã†ãŸã‚ã«ã€ãƒ©ã‚¤ãƒ–ã®ä¸­æ€§å­å›žæŠ˜å®Ÿé¨“ã‚’è‡ªå¾‹çš„ã«é§†å‹•ã™ã‚‹ã€‚
å®Ÿç·šã¯ã‚ªãƒ¼ã‚¯ãƒªãƒƒã‚¸å›½ç«‹ç ”ç©¶æ‰€ï¼ˆORNLï¼‰é«˜ãƒ•ãƒ©ãƒƒã‚¯ã‚¹åŒä½ä½“ç‚‰ï¼ˆHFIRï¼‰ã®HB-2Cãƒ“ãƒ¼ãƒ ãƒ©ã‚¤ãƒ³ã®åºƒè§’ä¸­æ€§å­å›žæŠ˜è¨ˆï¼ˆWAND2ï¼‰ã«å®Ÿè£…ã—ãŸã‚‚ã®ã§ã€ç ´ç·šã¯å›½ç«‹æ¨™æº–æŠ€è¡“ç ”ç©¶æ‰€ï¼ˆNISTï¼‰ä¸­æ€§å­ç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼ï¼ˆNCNRï¼‰ã®ãƒ“ãƒ¼ãƒ ãƒ©ã‚¤ãƒ³BT-4ã«è¿½åŠ å®Ÿè£…ã—ãŸèƒ½å‹•å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’ç¤ºã™ã€‚

ç±³å›½å›½ç«‹æ¨™æº–æŠ€è¡“ç ”ç©¶æ‰€ï¼ˆNISTï¼‰ä¸­æ€§å­ç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼ï¼ˆNCNRï¼‰ã®BT-4ãƒ“ãƒ¼ãƒ ãƒ©ã‚¤ãƒ³ã®ç‚¹æ¤œå‡ºå™¨ã¨ã‚ªãƒ¼ã‚¯ãƒªãƒƒã‚¸å›½ç«‹ç ”ç©¶æ‰€ï¼ˆORNLï¼‰é«˜ãƒ•ãƒ©ãƒƒã‚¯ã‚¹åŒä½ä½“ç‚‰ï¼ˆHFIRï¼‰ã®HB-2Cãƒ“ãƒ¼ãƒ ãƒ©ã‚¤ãƒ³ã®åºƒè§’ä¸­æ€§å­å›žæŠ˜è¨ˆï¼ˆWAND2ï¼‰ã®ä¸¡æ–¹ã«ANDiEãŒå°Žå…¥ã•ã‚Œã¾ã—ãŸã€‚
ANDiEã¯ã€äººé–“ã®ä»‹å…¥ãªã—ã«ã“ã‚Œã‚‰ã®è£…ç½®ã‚’åˆ¶å¾¡ã—ã€MnOã¨Fe1.09Teã®ä¸¡æ–¹ã®ç²‰æœ«è©¦æ–™ã®TNã‚’è‡ªå¾‹çš„ã«ç™ºè¦‹ã™ã‚‹ã“ã¨ã«æˆåŠŸã—ã€ãã®ãŸã‚ã®æ¸©åº¦ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¾“æ¥ã®ã‚¢ãƒ‰ãƒ›ãƒƒã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿé¨“ã¨æ¯”è¼ƒã—ã¦ç´„5åˆ†ã®1ã«å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã£ãŸã€‚
ã•ã‚‰ã«ã€ANDiEã¯ä»®èª¬æ¤œè¨¼ã‚’è¡Œã„ã€ç£æ°—æ§‹é€ ã®æ¸©åº¦ä¾å­˜æ€§ã«å¯¾ã—ã¦æ­£ã—ã„ç‰©ç†ãƒ¢ãƒ‡ãƒ«ï¼ˆ1æ¬¡ã€Isingåž‹2æ¬¡ã€Weissåž‹2æ¬¡ï¼‰ã‚’ç‰¹å®šã—ã¾ã™ã€‚
ãã—ã¦ã€ãã®ãƒ¢ãƒ‡ãƒ«ã‚’å°¤åº¦ã®é«˜ã„é †ã«ä¸¦ã¹ã€ä¸€ç•ªä¸Šã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠžã™ã‚‹ã€‚ã“ã®ã‚ˆã†ã«ã€ANDiEã¯ä¸­æ€§å­å›žæŠ˜å®Ÿé¨“ã®åŠ¹çŽ‡ã‚’é£›èºçš„ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚

## II. MATERIALS AND METHODS

### A. Algorithm

For the isothermal inference, we used model for the diffraction intensity in the 2Î¸ diffraction space range of interest constructed from two Pseudoâ€“Voigt peaks and a constant background.
The full model for the diffraction intensity in 2Î¸-space is given by
Equation(1)
where Î¶Mag and Î¶Struct are scaling factors, Ï‰Mag and Ï‰Struct are the peak locations in 2Î¸-space, and Î±Mag, Î³Mag, Î±Struct, and Î³Struct are the Pseudoâ€“Voigt peak shape parameters for the magnetic and structural peaks, respectively, and IBack is the background intensity.

As discussed Sec. IIIâ€‰A, we use the Weiss equation to predict the temperature dependence of the local magnetic moments during the autonomous experiment.30
With the assumption that the diffraction peak shape does not strongly change over the course of the experiment, the maximum intensity of the magnetic diffraction peak is proportional to the integrated intensity.
The full Weiss model for the temperature dependence of the magnetic diffraction intensity is then given by
Equation(2a)
Equation(2b)
where rootð‘š[] is the root finding operation of the expression in the square brackets with respect to m, m is the reduced magnetization, T is the temperature in kelvin, I(T) is the diffraction intensity, TN is the magnetic transition temperature, J is the quantum total angular momentum, M0 is a scaling parameter proportional to the maximum spontaneous magnetization, BJ(x) is the Brillouin function, and Bk is the background intensity.
Note that M0 in Eq. (2a) is a composite of the maximum spontaneous magnetization and the square root of the unknown proportionality constant between the diffraction intensity and the square of the magnetic moments.

To select the next temperature, temperature values are explored (with a step size of 0.5â€‰K) to identify the next temperature where the confidence interval (CI) of the model exceeds a threshold relative the Poissonian-like uncertainty predicted by the mean of the model.
Limiting the active learning scheme to increasing temperature avoids any hysteretic effects.
Once the temperature is above the upper confidence bound of TN, the confidence interval of the model no longer depends on temperature (as the background is the only parameter left to fit).
Large temperature steps above TN are then taken.

Once the full data set is collected in the autonomous experiment, ANDiE performs a post-processing hypothesis testing to determine which of the models discussed in Sec. III is the most likely.
The first-order model is given by 
Equation(3)
where K is the intensity scaling constant and Ïƒ is the full-width at half maximum of the Gaussian convolution of the step-function, which is used to describe the width of the transition.
Finally, the Ising model is given by 
Equation(4)
where Î² is the critical exponent.
Note that Eq. (4) is only valid near TN, which we have used Tâ€‰>â€‰0.5TN to enforce.

ANDiE performs the inference using each of the three models.
Note that the inference with the Ising model infers TN and, therefore, also the range in which the Ising model is valid.
To ensure a fair comparison of the log-likelihoods between each of the three models, once the Ising model inference is complete, we re-perform the inference of the first-order and Weiss models using only the data points that fall within the valid range of the Ising model.
If the Ising model is not the most likely given the data points within that range, we compare the first-order and Weiss models using the inference on the entire temperature range acquired by the autonomous experiment.

All parameters of each model are initialized with prior truncated normal distributions based on the physical limitations (e.g., TN cannot be negative) and estimates from experts.
ANDiE uses the DREAM sampler31 to perform the MCMC inference.
For each of the models (in both the isothermal and thermal inference), we use a Gaussian likelihood around the prospective curve to determine the probability of observing the data given the models.
The widths of these likelihood distributions are determined by model and the instrument uncertainties,32,33 which captures the highly heteroscedastic nature of these Poissonian-like processes.
The autonomous analysis of the neutron diffraction data shown here was enabled by data pipeline that automatically reduces neutron event data into spectra34 using the Mantid framework.35

The full algorithm was written in Python and implemented in a Jupyter notebook that analyzes the diffraction patterns, selects the next temperature, and communicates with data acquisition, without human intervention.
The ANDiE notebooks used during the autonomous experiments are available at https://github.com/usnistgov/ANDiE-v1_0.
The BUMPS library36 was used for the MCMC functions with the DREAM sampler.31
For the thermal inference, a numerical root-seeking algorithm from the sci-kit learn library37 is used to solve for the root of the Weiss equation at each step in the MCMC chain.

### B. Experimental set-up

Diffraction experiments were performed at the WAND2 HB-2C beamline at HFIR at ORNL using a wavelength of 1.4828â€‰Ã….
Initial algorithm development was using experiments performed at the BT-4 beamline at the NCNR at NIST.
The MnO powder was purchased from Sigma Aldrich (Cat. # 377201)*.
A description of the synthesis details of the Fe1.09Te powder sample can be found in Ref. 38.
Both MnO and Fe1.09Te powder samples were measured in Vanadium cans sealed under He-atmosphere.
To reach low temperatures, a top-loading closed cycle refrigerator with a variable temperature insert (VTI) with He-exchange gas was used.

## III. RESULTS AND DISCUSSION

### A. Autonomous discovery of magnetic transition behavior of MnO

In this first demonstration of an autonomous research neutron diffraction system, we initially consider the well-studied material MnO to ensure ANDiE can reproduce known results.
In Sec. IIIâ€‰B, we consider the more challenging material Fe1.09Te, which, as ANDiE discovers, has a sharp first-order transition.
These studies demonstrate the robustness of ANDiE and future studies can, therefore, confidently use ANDiE to study materials where the magnetic transition behavior is unknown.
There are some materials where the magnetic propagation vectorsâ€”and therefore diffraction peak positions in 2Î¸-spaceâ€”are strong functions of temperature.39,40
Additionally, the intensity of the magnetic contribution to the diffraction pattern is also a strong function of temperature, especially across the ordering temperature [compare Fig. 2(a) with Fig. 2(b)].
As a result, the isothermal model parameters can change dramatically as the temperature-dependence experiment progresses.
This motivates the need for a reliable algorithmic platform capable of capturing such diverse behavior.
Bayesian inference provides a robust, probabilistic method to describe the material at any one temperature and across temperatures.
Bayesian inference allows one to utilize prior knowledge to improve data analysis and prediction, and it provides a framework for uncertainty quantification and propagation.
In contrast to simpler methods such as least squares fitting, this Bayesian framework allows the parameters to be inferred from the data with more accurate uncertainties.
Data can be input with uncertainty bounds, and target parameters are output as probability distributions with expected value and uncertainty.
In particular, ANDiE uses MCMC-based Bayesian inference to extract the magnetic component from each isothermal diffraction measurement.
The use of MCMC inference for global optimization ensures high confidence in peak parameter determination despite the large range of potential parameters values.
MCMC is particularly well suited to avoiding the myriad of local minima present in diffraction data.41
In contrast, other optimization schemes, such as the Levenbergâ€“Marquardt algorithm, can perform well only when the initialization is close to the global minimum and can diverge otherwise.
Additionally, MCMC allows us to encode prior physics knowledge such as the Poissonian-like counting statistics of the measured intensities, thereby accounting for the highly heteroscedastic nature of the intensity as a function of diffraction angle (and of temperature, as shown in the next paragraph).
Furthermore, MCMC prior estimates of the parameters can be included, i.e., nuclear peak positions from previous x-ray diffraction measurements, or information from previous reports in the literature.
The active learning process begins with a previously identified range of interest for 2Î¸.
For MnO, we started with the detector 2Î¸ range of 28.0Â° to 37.0Â°, which includes the (111) nuclear peak and the nearby (32â€‰12â€‰12) magnetic peak.
ANDiE then infers probability distributions for the peak shape parameters including the locations, heights, half-widths at half maximum for both the Gaussian and Lorentzian components of Pseudoâ€“Voigt peaks, as well as a background term.
Figure 2 shows the results of this inference at 5.0â€‰K and at 129.5â€‰K.

FIG. 2.
: Isothermal inference for MnO.
Isothermal inference was performed on MnO diffraction data in the range of interest at the experiment temperature (T) of (a) 5.0â€‰K and (b) 129.5â€‰K.
The magnetic confidence interval in orange shows the confidence interval of the magnetic component of the isothermal model.
Note how the magnetic peak parameters (32â€‰12â€‰12) near 32.18Â° changes between the temperatures.
The global optimization MCMC algorithm infers an appropriate profile despite the large changes.
Error bars on the measured data points in blue represent one standard deviation and are smaller than the symbol size.

ANDiE uses the inferred peak parameter distributions at each isothermal measurement to predict the temperature dependence of the diffraction's magnetic component.
The magnetic component of neutron diffraction intensity is related to the square of the magnetic moment.29
Several models can describe the temperature dependence.
In this work, we consider a first-order phase transition model and the Ising and Weiss second-order phase transition models.
The first-order phase transition model is an error functionâ€”a step function convolved with a narrow Gaussian function.
Because this model only has a non-zero slope near TN, predictions made by inference are not informative for selecting subsequent temperature steps, i.e., there is no indication that the experiment temperature is approaching TN until it is within a few kelvin (i.e., within the Gaussian convolution).
Therefore, even if the material being studied is suspected to have first-order transition behavior, using a first-order model is not appropriate during the autonomous experiment.
Instead, ANDiE uses a second-order model to make predictions during the autonomous experiment.
A Bayes factor test is then used once all the data has been collected to determine if the material exhibits first-order behavior.

The second-order phase transition models do have non-zero slopes far below TN and, therefore, can be used to predict an appropriate temperature step.
However, the Ising model is only valid near TN, in the range 0.5TN < T < TN,42 whereas the Weiss model is valid across the entire temperature range below TN.
Therefore, regardless of the material being studied and the suspected behavior, ANDiE uses the Weiss model during the autonomous experiment to drive the data acquisition, and then in post-processing it determines the most appropriate model with the Bayes factor.
Example curves of each of these models are shown in Fig. 3.

FIG. 3.
: Example models for thermal inference.
There are several models for the temperature dependence of the magnetic component of the neutron diffraction intensity.
The black curve shows the first-order model.
The Ising model is shown in red, where the dashed region is outside the range of validity of this model.
The Weiss model is shown in blue.

For these reasonsâ€”regardless of the material being studiedâ€”ANDiE uses the Weiss model to select the temperature steps of subsequent measurements, propagating knowledge from low to high temperatures.
This physics-informed approach has several advantages over a more generic power law fitting or a surrogate ML model such as a Gaussian process.
First, the Weiss model constrains ANDiE to only physically meaningful solutions, i.e., positive temperature, positive intensity, and monotonic temperature dependence.
Second, we demonstrate that with the Weiss model, ANDiE focuses measurements in the most informative regions at low temperature and surrounding the transition temperature.
Furthermore, ANDiE uses a minimum number of measurements to properly characterize the curvature and background outside these regions.
We found this to be true regardless of the actual materials behavior and using only a broad prior estimation of the TN.
For materials with second order transitions, the Weiss model is flexible enough to drive the data collection to the informative temperatures.
In the case of a truly abrupt discontinuous first-order transition, discovering such a step-function is a daunting task that can only be solved iteratively with several cooling and warming cycles and ANDiE could be implemented to autonomize these iterations.
However, if there is a perturbation from ideal first-order behavior (i.e., from short-range order or the like) as is the case for many materials, the flexibility of the Weiss model allows ANDiE to collect more data near TN.
In this way, ANDiE uses the Weiss model to discover TN (with enough data to determine the transition behavior) from a single warming cycle.

Because neutron diffraction intensity obeys Poissonian-like counting statistics, the process is highly heteroscedastic, meaning that the uncertainty in the signal is highly non-uniform across the search domains.
The uncertainty (as estimated by the standard deviation of a Gaussian distribution using the continuous approximation) of the diffraction intensity is related to the square root of the diffraction intensity.
Common acquisition functions do not account for heteroscedasticity and tend to over-emphasize regions of high intensity, unnecessarily acquiring more data in these regions.
ANDiE, therefore, compares the confidence interval of the model (a value dependent on the number of measurements) to the uncertainty predicted from the intensity extrapolation.
ANDiE increases the temperature until that ratio is above some threshold which we call the Bravery factor.
The model variance is a measure of how well known the intensity is at each temperature given the data that has been measured.
The predicted uncertainty is a measure of how much we should expect to know about the value of intensity if a measurement is performed at that temperature.
The ratio of these two values represents how informative that measurement will be to the model.
Setting the Bravery factor determines a threshold on this ratio, above which measurements are considered useful.
Temperatures where the ratio is below the Bravery factor can be safely skipped, and the experiment temperature can be increased until that threshold is reached.
The Bravery factor therefore represents the user's risk tolerance and can change depending on the purpose of the experiment.
If little is known about the material, a high Bravery Factor might be appropriate to explore the space quickly.
If, however, the goal of the experiment is to fine tune the measurement of TN, then a smaller Bravery Factor might be appropriate so as to only take small temperature steps (i.e., measurements that are only moderately informative are still useful).

Figure 4 shows how ANDiE performed for the autonomous discovery of TN of MnO.
ANDiE chooses small temperature steps in the beginning of the autonomous experiment as there are little data to infer the temperature dependence.
As more data are acquired, ANDiE takes larger temperature steps until it approaches TN.
Near TN, the steep slope of the model naturally causes wide confidence intervals of the inference, and more data are acquired in the region.
In this way, ANDiE skips uninformative temperatures and quickly converges on TN.
After 14 temperature steps, ANDiE inferred that the experiment temperature was above TN.
In this region, the selection of further data points is arbitrary, and several measurements were taken at 10â€‰K steps.
The results of this inference at several stages are shown in Fig.4.
After 16 temperature steps, ANDiE reached the stopping criteria for the experiment.
ANDiE quickly converged on the most likely parameters.
As mentioned before, there is no universally agreed method for the traditional ad hoc scheduling, which is determined by the intuition of the researcher and is particularly difficult with small signals (i.e., from materials with small magnetic moments, small crystal samples or thin-film).
For the sake of comparison, an informed ad hoc schedule might take 0.5â€‰K steps within 10â€‰K of prior guess of TN, 2â€‰K steps within 20â€‰K of the prior guess of TN, and 5â€‰K steps otherwise, for a total of 74 temperature steps.
ANDiE, therefore, reduces the number of temperature steps required for the experiment by a factor of â‰ˆ5.

FIG. 4.
: Thermal inference snapshots for MnO.
The thermal inference step was performed during the autonomous experiment for temperature dependence of the MnO magnetic (32â€‰12â€‰12) reflection using the Weiss model.
Results are shown as determined after (a) one measurement, (b) after 12 measurements near the NÃ©el temperature (TN), and (c) after 16 measurements at the end of the autonomous experiment.
The mean of the posterior curves (MP) of the inference for each model is shown in red.
The best parameters (BP) for each model are shown in the black dashed curves, while the confidence intervals (CI) are shown as the gray envelope.
The vertical green line in each part shows the next temperature the algorithm selected to measure next.
The error bars on the measured data points are smaller than the makers shown in blue, and in (c) the confidence interval of the model is smaller than the linewidth of the mean of the posteriors.

After the autonomous experiment reaches the stopping criteria, ANDiE performs hypothesis testing to determine which of the models considered herein are more likely.
Since the Ising model is only valid near TN, it determines the range over which the model likelihoods will be compared.
Thus, ANDiE performs inference with the Ising model first.
Inference is then performed for the other models over the same temperature range.
If the Ising model is not the most likely over the appropriate range, then ANDiE compares the likelihoods of the first-order model and Weiss model over the entire data set.
Figure 5 shows the result of the Ising model inference, determined to be the most likely model, with an estimated TN of 120.81(56) K.
Table I summarizes the results for all models.
The uncertainties in the prediction of TN reflect the confidence of the model in that parameter given the data points.
These confidence intervals represent an uncertainty in the parameter only insofar as the model is physically applicable.
For example, in the case of MnO, the Weiss model is not likely physically meaningful.
This is, therefore, also true of uncertainty in TN as derived from the Weiss model for that sample.
The fact that the first-order and Weiss models have such unphysically low uncertainty in this prediction shows that adjusting TN further will not improve the fit to the data.
This is also reflected in the large negative log-likelihoods of these models showing that they are not appropriate for the data.
In contrast, the Ising model is appropriate, as evidenced by the higher log-likelihood.
Therefore, the confidence in the TN parameter from the Ising model inference is a good measure of the uncertainty in TN.
Following this, ANDiE concludes that MnO is an Ising-type antiferromagnet with a TN of 120.81(56) K, consistent with the literature.42â€“44

FIG. 5.
: Ising model hypothesis testing.
Ising model inference was performed on the temperature dependence of the MnO magnetic (32â€‰12â€‰12) reflection as performed the post-processing hypothesis testing step and determined to be the most likely model.
The error bars on the measured data points are smaller than the makers, and the confidence interval of the model is smaller than the linewidth of the mean of the posteriors.

TABLE I.
: Thermal inference results.
The predicted NÃ©el temperature (TN) and model log-likelihoods are used in the post-processing hypothesis testing for the autonomous neutron diffraction study of MnO and Fe1.09Te with WAND2 at HB-2C at HFIR at ORNL.
Note that the Ising model is only valid near TN.
The uncertainty in the prediction of TN reflects the confidence of that model in that parameter given the data.
These confidence intervals are good measures of the uncertainty only when the models are physically appropriateâ€”as evidenced by the higher log-likelihoods.
Note that uncertainty is presented in compact notation where (##) represents the uncertainty in the last two digits of the value.
Boldface denotes the results of the most likely model for each material as concluded by ANDiE.

### B. Autonomous Discovery of Magnetic Transition Behavior of Fe1.09Te

Having validated its effectiveness on determining the magnetic transition of MnO, a well-studied material with a second-order transition, ANDiE was then implemented on the more challenging Feâ€“Te system.
Fe1+xTe has complicated magnetic behavior as a function of the interstitial iron, i.e., x in the chemical formula.45
Below â‰ˆ11% interstitial Fe, there is a first-order phase transition to an antiferromagnetic phase.
TN of this transition in Fe1+xTe ranges from 70â€‰K at xâ€‰=â€‰0% to 52â€‰K at xâ€‰=â€‰11%.
The precise determination of TN for Fe1.09Te is a challenging task since abrupt step-like first-order transition could occur over a wide range of temperatures.
Indeed, Fig. 6(a) shows sharp this transition is in the diffraction intensity of the magnetic (12â€‰0â€‰12) reflection of Fe1.09Te at 69.436(55) K, as acquired by an ad hoc measurement schedule (carried out as a separate experiment after the autonomous run).
ANDiE, using the Weiss-type transition model as a prior, discovered this transition in only 14 measurements.
This is an improvement over the ad hoc schedule by a factor of â‰ˆ4.
A discussion of the time savings, computational considerations, as well as a video capturing the evolution of inference as the autonomous experiment was performed are available in the supplementary material.
We note that the code currently used to implement the ANDiE is developmental, and while it is robust enough to demonstrate the autonomous decision making, future work could use parallel computing to speed computation (see discussion of computational time in the supplementary material, Sec. II).
After the data are collected, ANDiE then performs the model comparison between the Ising, Weiss, and first-order models [as shown in Figs. 6(b)â€“6(f)].
It can be seen that while the Ising model [Fig. 6(d)] has reasonably good agreement with the data, the first-order model over the same temperature range [Fig. 6(f)] provides a better description of the behavior.
This is especially evident in the region near the TN.
This low intensity data have low uncertainty owing the Poisonian-like statistics.
As a result of propagating this measurement uncertainty through this Bayesian framework, a few counts deviation between the model and the measurement at low intensity is far less likely than a few counts deviation at high intensity.
Therefore, deviations between the model and the data are more heavily penalized at low intensity in the calculation of the model likelihood.
The summary of the log-likelihoods and predicted transition temperatures used for the model selection is presented in Table I.
Here, it is worth noting that, as was the case above, the confidence intervals from the models are a good measure of the uncertainty only when the model is physically appropriate.
Considering the data from full temperature range, the high log-likelihood of the first-order model indicates that this model is the most likely.
ANDiE, therefore, correctly inferred first-order transition behavior with TN of 68.58(16) K, which agrees with that measured by the ad hoc schedule.
This magnetic ordering behavior is similar to what is expected from earlier reports of the Fe1+xTe phase diagram.45
ANDiE is, therefore, able to discover the behavior of the magnetic order parameter in very few measurements even when the actual behavior is far from the prior estimation.

FIG. 6.
: Autonomous measurement and hypothesis testing vs ad hoc schedule.
The intensity of magnetic (12â€‰0â€‰12) reflection of Fe1.09Te as determined from the isothermal inference are shown in blue.
The ad hoc schedule is shown in (a).
The hypothesis testing was performed using the inference of the (b) Weiss, (c) first-order, and (d) Ising models, respectively, on the autonomously acquired measurements.
The (e) Weiss and (f) first-order models were re-trained on the data where experiment temperature greater than one half the estimate of the NÃ©el temperature (TN) from the Ising inference (i.e., Tâ€‰>â€‰0.5TN).
The mean of the posterior curves (MP) of the inference for each model is shown in red.
The best parameters (BP) for each model are shown in the black dashed curves, while the confidence intervals (CI) are shown as the gray envelope.
The Weiss model was used to drive the autonomous experiment.
The first-order model was determined to be the most likely for this transition of Fe1.09Te.
The error bars on the measured data points shown in blue are smaller than the makers, and the confidence interval of the model is smaller than the linewidth of the mean of the posteriors.

These results show that ANDiE is capable of autonomously discovering TN of a material and performing basic model selection in the first live autonomously driven neutron diffraction experiments.
This demonstration goes beyond a simple proof-of-concept by making a discovery of TN and transition behavior on a previously under-studied material.
Furthermore, we have demonstrated the efficacy of a single pass of ANDiE, which can accomplish the goal of discovering TN to less than a degree and perform simple model selection.
An accurate determination of critical exponents is beyond the scope of this prototyping work, but ANDiE could be generalized to accomplish that task.
Future work can include conditions for cooling back to base temperature for subsequent runs of ANDiE with updated priors in order to perform more difficult discovery tasks.

## IV. CONCLUSION

We have developed the autonomous neutron diffraction explorer (ANDiE), a system for controlling neutron diffraction experiments for the discovery of the magnetic transition temperature.
The system presented here provides a Bayesian approach to selecting the experiment temperatures which not only provides probabilistic predictions but also encodes the relevant physics to the problem at hand.
We have demonstrated the versatility of ANDiE, which is capable of discovering the magnetic transition temperature of material systems with differing magnetic behaviors despite always driving the acquisition of data with the Weiss model.
Even though this model might not be the expected behavior of the material being studied, it is useful in choosing the next temperatures to efficiently discover the transition temperature.
ANDiE can accelerate the data acquisition by reducing the number of temperature steps by nearly a factor of 5 and can subsequently perform hypothesis testing to determine the governing physical principles of the transition.
The hypothesis testing after the data is acquired correctly identified the Ising-type transition in MnO at 120.81(56) K.
Even in the more challenging case of Fe1.09Te with an abrupt step-like first-order transition, ANDiE was able to efficiently drive the experiment, requiring only 14 measurements to discover the first-order transition behavior at 68.52(16) K.
As currently implemented, ANDiE compares the likelihood between the three previously discussed models.
Extending hypothesis testing to additional user-determined models is a straightforward task.
Furthermore, the methods implemented in ANDiE can be easily expanded to a variety of neutron-based experiments.
We expect the experiment speedup to increase with the dimensionality of the experiment such as implementing the active learning in the diffraction angle space on point-detector instruments such as the BT-4 at NCNR for rapid search of diffraction peaks.
Similarly, using our active learning scheme in the applied magnetic field space would reduce the number of measurements for those experiments.
The approach used by ANDiE is further generalizable to other measurements (such as x-ray diffraction or functional property measurements) where a generally applicable physical model can be used to efficiently navigate costly experimental conditions.
The autonomous system presented here exemplifies the potential of rapid neutron scatting experiments for accelerating materials discovery.

## LICENCE

Article by A. McDannald, M. Frontzek, A. T. Savici, M. Doucet, E. E. Rodriguez, K. Meuse, J. Opsahl-Ong, D. Samarov, I. Takeuchi, W. Ratcliff, & A. G. Kusne, "On-the-fly autonomous control of neutron diffraction via physics-informed Bayesian active learning", _Applied Physics Reviews_, **9** 021408 (2022). [https://doi.org/10.1063/5.0082956](https://doi.org/10.1063/5.0082956) / Cited under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) / Translated by [Yuki Sakishita](https://y-saki26.github.io/pages/).
